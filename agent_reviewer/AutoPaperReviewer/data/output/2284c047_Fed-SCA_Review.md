作为一名在 AI/CV 领域深耕 20 年并多次担任顶级会议（CVPR, NeurIPS, ICML）Senior Area Chair 的审稿人，我对该论文《Fed-SAP: Statistics-Aligned Personalization for Federated Attention on Non-IID Data》进行了深度审阅。

以下是我的审稿报告：

---

### 1. 核心内容总结 (Summary)

*   **发现的问题**：在非独立同分布（Non-IID）的联邦学习场景下，盲目聚合注意力模块（如 SE 模块）会导致“有害聚合”。作者通过实验发现，卷积层（Conv）学习的是通用知识，而 SE 模块的激励层（SE-E）具有高度的个性化特征，直接聚合会导致模型性能下降 [Page 1, 2]。
*   **提出的解决办法**：提出 **Fed-SAP** 框架。其核心包含两部分：
    1.  **个性化 SE (pSE)**：聚合通用的卷积层参数，而将 SE-E 层留在本地进行个性化训练 [Page 2, 3]。
    2.  **全局统计正则化 (GSR)**：为解决个性化层输入（Squeeze 统计向量）存在的统计偏差，引入额外的 L2 损失函数，强制本地卷积层在提取特征时将其通道统计特性与服务器维护的全局统计量 $S_G$ 对齐 [Page 2, 3]。
*   **实验设计与结果**：在 CIFAR-10 和 Fashion-MNIST 数据集上，使用 MobileNetV3-Small 作为骨干网络，模拟了不同 Dirichlet 分布（$\alpha$ = 0.5, 0.8, 1.0）的 Non-IID 场景 [Page 4, 5]。对比了 FedAvg, FedProx, FedBN 等 Baseline，结果显示 Fed-SAP 在 Non-IID 程度最高时（$\alpha=0.5$）提升最显著，CIFAR-10 上达到 75.32% 的准确率 [Page 6]。

### 2. 优点与先进性 (Strengths)

1.  **洞察力敏锐**：论文通过实验（图 1）量化了卷积层与 SE-E 层在联邦学习过程中的余弦相似度差异，为“为什么要个性化注意力模块”提供了直观的实证支持 [Page 2]。
2.  **方法论的协同性**：作者没有简单地停留在“参数隔离”层面，而是敏锐地察觉到个性化层与全局层之间的“输入统计失配”问题，提出的 GSR 机制试图从特征源头缓解漂移，逻辑链条较为完整 [Page 3]。
3.  **低通信开销**：GSR 仅交换通道维度的统计向量（C 维），相比于模型参数，其通信成本几乎可以忽略不计 [Page 4]。

### 3. 批判性不足与疑问 (Weaknesses & Questions)

*   **数据集 (Datasets) 的说服力极度匮乏**：
    *   作为一篇针对 2025 年会议投稿潜力的论文（参考文献已引用至 2025 年 [Page 7]），仅在 CIFAR-10 和 Fashion-MNIST 这两个“玩具级”数据集上验证是不够的。
    *   **质疑**：SE 模块在复杂任务（如 ImageNet-1K 或大规模目标检测）中的表现与在简单分类任务中完全不同。在简单数据集上，通道统计量可能极易对齐，但在高维复杂分布下，GSR 的 L2 约束是否会破坏特征的判别力？原文未提及在大规模数据集上的表现。

*   **数学/理论 (Theory) 的严谨性缺失**：
    *   **公式 (6) 的潜在冲突**：GSR 损失函数 $L_{GSR,k} = \sum ||s_{batch,l} - S_{G,l}||^2_2$ [Page 3]。作者宣称这能“净化”输入，但从优化角度看，这实际上是在特征空间施加强大的先验约束。
    *   **逻辑断层**：如果本地数据分布本身就极度偏离全局（例如 Client A 只有“猫”），强制其特征统计量 $s_{batch}$ 趋向全局平均值 $S_G$（包含所有类别的平均特征），是否会导致卷积层提取的特征失去对本地类别的判别性？论文在“Representation Specificity Analysis”部分仅进行了定性描述 [Page 4]，缺乏严格的数学证明或消融实验来展示这种“对齐”与“判别力”之间的 Trade-off。

*   **实验完备性 (Experiments) 存在漏洞**：
    *   **Baseline 缺失**：论文对比了 FedBN [Page 6]，但 FedBN 针对的是 BN 层的个性化。在个性化联邦学习（pFL）领域，近两年有大量基于架构解耦或正则化的方法（如 FedRep, Ditto, FedROD）。
    *   **质疑**：为什么不与专门针对注意力机制个性化的方法进行对比？仅对比 FedAvg 和 FedProx 这种老旧方法，难以体现 Fed-SAP 的 SOTA 地位。
    *   **超参数 $\lambda$ 的敏感性**：表 II 显示 $\lambda$ 从 1.0 变到 2.0 时准确率从 69.26% 跃升至 75.11%，而变到 5.0 时又跌回 68.9% [Page 5]。这种极度的参数敏感性暗示了该方法在实际生产环境中的鲁棒性可能很差。

*   **逻辑自洽性 (Consistency) 质疑**：
    *   作者在引言中提到“强制‘一刀切’的全局模型是不合理的” [Page 1]，但 GSR 机制的核心却是强制本地特征统计量去对齐一个“一刀切”的全局统计向量 $S_G$ [Page 3]。
    *   **矛盾点**：这是否在方法论上陷入了“为了解决聚合偏差而引入了另一种形式的全局强制一致性”的怪圈？

*   **相关工作遗漏**：
    *   论文未讨论关于“特征偏移（Feature Shift）”与“标签偏移（Label Shift）”的本质区别。SE 模块的统计量 $s$ 直接受标签分布影响，GSR 本质上是在做标签分布倾斜下的特征对齐，这与 Domain Adaptation 中的某些工作高度重合，但文中并未引用相关文献。

### 4. 综合评分 (Rating)

*   **分数**：**2 / 5 (Weak Reject)**
*   **定级理由**：论文对 SE 模块在联邦学习中的行为观察具有一定价值，但实验设计过于单薄（数据集过小、Baseline 过时），且核心方法 GSR 存在严重的逻辑悖论——在强调个性化的同时强制特征统计量全局一致，却未能从数学或深度实验上证明这种强制一致性不会损害本地任务的判别力。

### 5. 其他意见 (Other Comments)

1.  **图表问题**：图 1 的坐标轴标签较小，且未注明是在哪一个具体的卷积层提取的相似度。
2.  **算法细节**：算法 1 中第 27 行提到在整个 $D_k$ 上计算 $S_{up,k}$ [Page 4]，这在实际大规模边缘设备上会带来巨大的计算负担，论文应讨论其计算开销。
3.  **参考文献**：引用了大量 2025 年的文献（如 [3, 4, 5, 12, 14]），考虑到目前的时间节点，这些文献可能尚未正式发表或处于预印本阶段，引用比例过高可能影响学术严肃性。